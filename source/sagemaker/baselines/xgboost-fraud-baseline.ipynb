{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline XGBoost Model\n",
    "## Training Gradient Boosted trees with node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_data\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "\n",
    "train_X, train_y, test_X, test_y = get_data()\n",
    "\n",
    "buf = io.BytesIO()\n",
    "dump_svmlight_file(train_X.values[:, 1:], train_y, buf)\n",
    "buf.seek(0);\n",
    "filename = 'xgboost-fraud-dataset.libsvm'\n",
    "with open(filename,'wb') as out:\n",
    "    out.write(buf.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "from sagemaker_graph_fraud_detection import config\n",
    "\n",
    "role = config.role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = config.solution_bucket\n",
    "prefix = 'xgboost-fraud-detection'\n",
    "\n",
    "s3_train_data = S3Uploader.upload(filename, 's3://{}/{}/{}'.format(bucket, prefix,'train'))\n",
    "print('Uploaded training data location: {}'.format(s3_train_data))\n",
    "\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SageMaker XGBoost Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', repo_version='0.90-2')\n",
    "scale_pos_weight = np.sqrt((len(train_y) - sum(train_y))/sum(train_y))\n",
    "\n",
    "hyperparams = {\n",
    "        \"max_depth\":5,\n",
    "        \"subsample\":0.8,\n",
    "        \"num_round\":100,\n",
    "        \"eta\":0.2,\n",
    "        \"gamma\":4,\n",
    "        \"min_child_weight\":6,\n",
    "        \"silent\":0,\n",
    "        \"objective\":'binary:logistic',\n",
    "        \"eval_metric\":'f1',\n",
    "        \"scale_pos_weight\": scale_pos_weight\n",
    "}\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role,\n",
    "                                    hyperparameters=hyperparams,\n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path=output_location,\n",
    "                                    sagemaker_session=session)\n",
    "xgb.fit({'train': s3_train_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "predictor = xgb.deploy(initial_instance_count=1,\n",
    "                       endpoint_name=\"xgboost-fraud-endpoint\",\n",
    "                       instance_type='ml.m4.xlarge')\n",
    "\n",
    "# Specify input and output formats.\n",
    "predictor.content_type = 'text/csv'\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(current_predictor, data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, current_predictor.predict(array).decode('utf-8')])\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "raw_preds = predict(predictor, test_X.values[:, 1:])\n",
    "y_preds = np.where(raw_preds > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def print_metrics(y_true, y_predicted):\n",
    "\n",
    "    cm  = confusion_matrix(y_true, y_predicted)\n",
    "    true_neg, false_pos, false_neg, true_pos = cm.ravel()\n",
    "    cm = pd.DataFrame(np.array([[true_pos, false_pos], [false_neg, true_neg]]),\n",
    "                                    columns=[\"labels positive\", \"labels negative\"],\n",
    "                                    index=[\"predicted positive\", \"predicted negative\"])\n",
    "    \n",
    "    acc = (true_pos + true_neg)/(true_pos + true_neg + false_pos + false_neg)\n",
    "    precision = true_pos/(true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
    "    recall = true_pos/(true_pos + false_neg) if (true_pos + false_neg) > 0 else 0\n",
    "    f1 = 2*(precision*recall)/(precision + recall) if (precision + recall) > 0 else 0\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(pd.DataFrame(cm, columns=[\"labels positive\", \"labels negative\"], \n",
    "                       index=[\"predicted positive\", \"predicted negative\"]))\n",
    "    print(\"f1: {:.4f}, precision: {:.4f}, recall: {:.4f}, acc: {:.4f}\".format(f1, precision, recall, acc))\n",
    "    print()\n",
    "    \n",
    "def plot_roc_curve(fpr, tpr, roc_auc):\n",
    "    f = plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Model ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "print_metrics(test_y, y_preds)\n",
    "fpr, tpr, _ = roc_curve(test_y, y_preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plot_roc_curve(fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

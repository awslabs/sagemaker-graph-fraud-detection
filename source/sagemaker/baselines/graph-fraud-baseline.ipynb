{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Graph Model\n",
    "\n",
    "## Connected Subgraphs as a measure of activity aggregation for detecting fraud accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading labels and test accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prefix = '../processed-data/'\n",
    "user_to_label = pd.read_csv(data_prefix + \"tags.csv\").set_index('userId')\n",
    "with open(data_prefix + \"test_users.csv\", \"r\") as fh:\n",
    "        new_users_test = [line.strip() for line in fh]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading edgelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_df = pd.read_csv(\"data/relations.csv.gz\", sep='\\t', compression='gzip', \n",
    "                           names=[\"day\", \"ms\", \"src\", \"dst\", \"relation\"])\n",
    "edges = relations_df[['src', 'dst']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from(zip(edges.src.values, edges.dst.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_to_connected_graph_size = {}\n",
    "connected_subgraphs = nx.connected_component_subgraphs(G)\n",
    "\n",
    "num_components = 0\n",
    "for subgraph in connected_subgraphs:\n",
    "    num_v = subgraph.order()\n",
    "    num_components += 1\n",
    "    for node in subgraph:\n",
    "        node_to_connected_graph_size[node] = num_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of connected components is {}\".format(num_components))\n",
    "print(\"Size of largest connected component is {}\".format(max(node_to_connected_graph_size.values())))\n",
    "print(\"Distribution of conneted component sizes is {}\".format(Counter(node_to_connected_graph_size.values())))\n",
    "plt.hist(np.log10(list(node_to_connected_graph_size.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [2, 3, 4, 5, 10]\n",
    "baseline_predictions = {thresh: [] for thresh in thresholds}\n",
    "for user in map(int, new_users_test):\n",
    "    for thresh in thresholds:\n",
    "        if user not in node_to_connected_graph_size:\n",
    "            baseline_predictions[thresh].append(0)\n",
    "        else:\n",
    "            pred = 1 if node_to_connected_graph_size[user] > thresh else 0\n",
    "            baseline_predictions[thresh].append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, labels):\n",
    "    true_positives = sum([pred for (i, pred) in enumerate(predictions) if pred and labels[i]])\n",
    "    false_positives = sum([pred for (i, pred) in enumerate(predictions) if pred and not labels[i]])\n",
    "    false_negatives = len([pred for (i, pred) in enumerate(predictions) if not pred and labels[i]])\n",
    "    true_negatives = len([pred for (i, pred) in enumerate(predictions) if not pred and not labels[i]])\n",
    "    \n",
    "    confusion_matrix = np.array([[true_positives, false_positives], [false_negatives, true_negatives]])\n",
    "    accuracy = (true_positives + true_negatives)/len(labels)\n",
    "    precision = true_positives/(true_positives + false_positives)\n",
    "    recall = true_positives/(true_positives + false_negatives)\n",
    "    f1 = 2*(precision*recall)/(precision + recall)\n",
    "    \n",
    "    return (confusion_matrix, f1, accuracy, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [user_to_label.loc[int(user)].label for user in new_users_test]\n",
    "for thresh in baseline_predictions:\n",
    "    print(\"======= Baseline metrics with thresholds at {}\".format(thresh))\n",
    "    confusion_matrix, f1, accuracy, precision, recall = compute_metrics(baseline_predictions[thresh], true_labels)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(pd.DataFrame(confusion_matrix, columns=[\"labels positive\", \"labels negative\"], index=[\"predicted positive\", \"predicted negative\"]))\n",
    "    print(\"f1: {:.4f}, precision: {:.4f}, recall: {:.4f}, acc: {:.4f}\".format(f1, precision, recall, accuracy))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
